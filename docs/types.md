# Type System Documentation

## Overview


This project implements a **dual type system** approach to handle the separation between frontend application logic and edge function processing. The type system is designed to maintain clear boundaries between client-side UI requirements and server-side AI processing while ensuring type safety across the entire application.

### Key Design Principles

1. **Separation of Concerns**: Frontend types focus on UI/UX needs, while edge function types handle AI processing
2. **Type Safety**: Strict TypeScript typing ensures compile-time safety
3. **Flexibility**: Types can evolve independently based on their domain requirements
4. **Clarity**: Clear naming conventions distinguish between frontend and edge function types

## Frontend Types (app/types/photo-session.ts)

The frontend types are designed to support the user interface and client-side application logic.

### PhotoShootContext

```typescript
interface PhotoShootContext {
  userGoal: string;
  themes: string[];
  environments: string[];
  shotTypes: string[];
  tips: string[];
  stage: 'goals' | 'shots' | 'locations' | 'complete';
}
```

**Purpose**: Manages the multi-stage user interaction flow for creating a photo session plan.

**Design Decisions**:
- `stage` field tracks the current step in the UI wizard
- Arrays of strings provide flexible categorization for themes and environments
- `userGoal` captures the high-level intent in natural language
- Optimized for progressive disclosure and user guidance

### Location

```typescript
interface Location {
  name: string;
  type: string;
  time: string;
  weather: string;
  accessibility: string;
  features: string[];
  coordinates: {
    lat: number;
    lng: number;
  };
}
```

**Purpose**: Represents photography locations with map integration capabilities.

**Design Decisions**:
- Includes `coordinates` for map rendering and navigation
- `weather` and `time` fields for quick reference
- `features` array for highlighting location benefits
- Simplified for display in location cards and lists

### Shot

```typescript
interface Shot {
  title: string;
  description: string;
  time: string;
  location: string;
  equipment: string[];
  settings: string;
  tips: string;
  imagePrompt: string;
}
```

**Purpose**: Represents individual shots in a user-friendly format for the shot list UI.

**Design Decisions**:
- `title` and `description` for clear shot identification
- `settings` as a string for flexible camera configuration display
- `tips` field for user guidance
- `imagePrompt` preserved for potential image generation

## Edge Function Types (supabase/functions/_shared/types.ts)

The edge function types are optimized for AI processing and API communication.

### EdgePhotoShootContext (PhotoShootContext in edge functions)

```typescript
interface PhotoShootContext {
  shootType: 'portrait' | 'landscape' | 'product' | 'event' | 'street' | 'fashion';
  mood: string[];
  timeOfDay: string;
  subject: string;
  duration: string;
  equipment?: string[];
  experience: 'beginner' | 'intermediate' | 'professional';
  specialRequests?: string;
}
```

**Purpose**: Structured data for AI prompt generation and session planning.

**Design Decisions**:
- `shootType` uses strict enum for consistent AI responses
- `experience` level helps tailor technical recommendations
- Optional fields (`equipment`, `specialRequests`) for flexibility
- Optimized for JSON parsing from AI responses

### EdgeLocation (Location in edge functions)

```typescript
interface Location {
  name: string;
  address?: string;
  description: string;
  bestTime: string;
  lightingNotes: string;
  accessibility: string;
  permits: string;
  alternatives: string[];
}
```

**Purpose**: Detailed location information generated by AI for photography planning.

**Design Decisions**:
- `lightingNotes` for technical photography guidance
- `permits` field for legal compliance
- `alternatives` array for backup options
- No coordinates (added later if needed for mapping)

### EdgeShot (Shot in edge functions)

```typescript
interface Shot {
  locationIndex: number;
  shotNumber: number;
  imagePrompt: string;
  poseInstruction: string;
  technicalNotes: string;
  equipment: string[];
  storyboardImage?: string;
}
```

**Purpose**: Technical shot specifications for AI-generated photography plans.

**Design Decisions**:
- `locationIndex` links shots to specific locations
- `poseInstruction` for subject direction
- `technicalNotes` for camera settings and composition
- Optional `storyboardImage` for visual reference

### Webhook Request Types

The edge function handles various request types through a flexible structure:

```typescript
interface WebhookRequest {
  stage?: 'context' | 'locations' | 'storyboard' | 'full';
  conversationId?: string;
  transcript?: string;
  mockContext?: string;
  context?: PhotoShootContext;
  locations?: Location[];
  generateImages?: boolean;
}
```

**Purpose**: Supports different entry points and processing stages for the AI pipeline.

**Variations**:
1. **Conversation Processing**: `{ conversationId: string }`
2. **Direct Transcript**: `{ transcript: string }`
3. **Mock Testing**: `{ mockContext: 'portrait' | 'landscape' }`
4. **Stage Processing**: Include `stage` with optional data from previous stages

## Type Conversion Patterns

### When Conversions Happen

1. **After AI Processing**: Edge function types are converted to frontend types when data returns to the client
2. **Before Storage**: Frontend types may be stored with additional UI state
3. **For Display**: Edge function data is enriched with UI-specific fields

### What Gets Transformed

#### Context Conversion (Edge → Frontend)
```typescript
// Edge function returns:
{
  shootType: 'portrait',
  mood: ['dramatic', 'moody'],
  timeOfDay: 'golden hour',
  subject: 'musician',
  // ...
}

// Frontend receives and transforms to:
{
  userGoal: 'Portrait shoot for musician',
  themes: ['dramatic', 'moody'],
  environments: ['urban', 'industrial'],
  shotTypes: ['portrait', 'environmental'],
  tips: ['Use golden hour lighting', '...'],
  stage: 'complete'
}
```

#### Location Conversion (Edge → Frontend)
```typescript
// Edge function returns detailed location
// Frontend adds coordinates and simplifies for display
location.coordinates = await geocodeAddress(edgeLocation.address);
location.type = categorizeLocation(edgeLocation.description);
```

#### Shot Conversion (Edge → Frontend)
```typescript
// Edge function returns technical shot
// Frontend creates user-friendly version
shot.title = `Shot ${edgeShot.shotNumber}`;
shot.location = locations[edgeShot.locationIndex].name;
shot.settings = formatTechnicalNotes(edgeShot.technicalNotes);
```

### Why the Separation Exists

1. **Domain Optimization**: Each type system is optimized for its specific use case
2. **API Flexibility**: Edge functions can evolve independently from UI
3. **Type Safety**: Prevents UI concerns from leaking into AI processing
4. **Maintainability**: Changes to UI don't affect AI logic and vice versa

## Session Types

### Session Interface

```typescript
interface Session {
  id: string;
  status: 'initial' | 'conversation' | 'processing' | 'complete';
  conversationId?: string;
  context?: EdgePhotoShootContext;
  locations?: EdgeLocation[];
  shots?: EdgeShot[];
  createdAt: string;
  title?: string;
}
```

**Purpose**: Manages the complete lifecycle of a photo planning session.

### Status Flow

1. **`initial`**: Session created, waiting for user interaction
2. **`conversation`**: User engaged with AI assistant
3. **`processing`**: AI processing conversation and generating plan
4. **`complete`**: Plan generated and ready for viewing

**Status Transitions**:
```
initial → conversation → processing → complete
```

## Type Validation

### Required vs Optional Fields

#### Always Required
- Identifiers: `id`, `name`, `title`
- Core data: `shootType`, `mood`, `subject`
- UI state: `stage`, `status`

#### Conditionally Optional
- `conversationId`: Only after AI conversation
- `equipment`: User may not specify gear
- `coordinates`: Added after geocoding
- `storyboardImage`: Only if image generation requested

### Type Guards and Validation Functions

While the codebase doesn't currently implement explicit type guards, here are recommended patterns:

```typescript
// Type guard for Session
function isCompleteSession(session: Session): session is Session & {
  context: EdgePhotoShootContext;
  locations: EdgeLocation[];
  shots: EdgeShot[];
} {
  return session.status === 'complete' && 
         !!session.context && 
         !!session.locations && 
         !!session.shots;
}

// Validation for AI responses
function validatePhotoShootContext(data: any): PhotoShootContext {
  const required = ['shootType', 'mood', 'timeOfDay', 'subject', 'duration', 'experience'];
  for (const field of required) {
    if (!data[field]) throw new Error(`Missing required field: ${field}`);
  }
  return data as PhotoShootContext;
}
```

## Best Practices

### When to Use Which Types

1. **Use Frontend Types When**:
   - Building UI components
   - Managing client-side state
   - Displaying data to users
   - Handling user interactions

2. **Use Edge Function Types When**:
   - Processing AI responses
   - Making API calls to edge functions
   - Parsing webhook data
   - Generating prompts for AI

### Adding New Types

1. **Determine the Domain**: Is it UI-focused or AI-processing focused?
2. **Choose the Right File**: 
   - UI types → `app/types/photo-session.ts`
   - AI types → `supabase/functions/_shared/types.ts`
3. **Consider Conversion**: Will the type need transformation between domains?
4. **Document Purpose**: Add JSDoc comments explaining the type's role

### Maintaining Type Safety

1. **Avoid `any` Types**: Use specific types or `unknown` with type guards
2. **Use Strict Mode**: TypeScript strict mode is enabled project-wide
3. **Validate External Data**: Always validate data from AI responses
4. **Type Imports**: Use type imports to avoid runtime dependencies

## Examples of Type Usage

### Creating a New Session
```typescript
// In SessionProvider
const createSession = (id: string): Session => ({
  id,
  status: 'initial',
  createdAt: new Date().toISOString(),
});
```

### Processing Webhook Response
```typescript
// In webhook handler
const response = await fetch('/api/webhook', {
  body: JSON.stringify({
    stage: 'full',
    conversationId: session.conversationId,
    generateImages: true
  })
});

const data = await response.json();
// data contains EdgePhotoShootContext, EdgeLocation[], EdgeShot[]
```

### Converting for Display
```typescript
// In UI component
const displayShots = edgeShots.map((shot, index) => ({
  title: `Shot ${shot.shotNumber}`,
  description: shot.poseInstruction,
  location: locations[shot.locationIndex].name,
  time: locations[shot.locationIndex].bestTime,
  equipment: shot.equipment,
  settings: shot.technicalNotes,
  tips: 'Follow the pose instructions carefully',
  imagePrompt: shot.imagePrompt
}));
```

### Type-Safe API Calls
```typescript
// API function with proper typing
async function generatePhotoSession(
  conversationId: string
): Promise<{
  context: EdgePhotoShootContext;
  locations: EdgeLocation[];
  shots: EdgeShot[];
}> {
  const response = await fetch('/api/elevenlabs-webhook', {
    method: 'POST',
    body: JSON.stringify({ conversationId, stage: 'full' })
  });
  
  if (!response.ok) throw new Error('Failed to generate session');
  
  const data = await response.json();
  return {
    context: data.context,
    locations: data.locations,
    shots: data.shots
  };
}
```

## Future Considerations

1. **Runtime Validation**: Implement zod or similar for runtime type validation
2. **Type Versioning**: Consider versioning types for API compatibility
3. **Shared Types**: Extract truly common types to a shared location
4. **Type Generation**: Consider generating types from API schemas
5. **Error Types**: Define specific error types for better error handling